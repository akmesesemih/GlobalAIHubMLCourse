{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 1 - Semih AKMESE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) How would you define Machine Learning ?\n",
    "- ML is the computer modeling of systems that make predictions by making inferences from data with mathematical and statistical operations. There many ML algorithms speficed for various problems. \n",
    "\n",
    "ML is basically divided into three groups according to the learning method; Supervised, Unsupervised and Reinforcement.\n",
    "\n",
    "\n",
    "2) What are the differences between Supervised and Unsupervised Learning? Specify example 3 algorithms for each of these.\n",
    "- The basic difference is about label \n",
    "- In supervised learning we train the machine using data which is \"labeled\". It means some data is already tagged with correct answer. \n",
    "- Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.\n",
    "\n",
    "- Supervised Learning Algorithms \n",
    "- Linear Regression\n",
    "- Classification \n",
    "    + Logistic Regression\n",
    "    + KNN\n",
    "    + Decision Tree\n",
    "    + Support Vector Machine (SVM) \n",
    "    + Naive Bayes \n",
    "    \n",
    "- Unsupervised Learning Algorithms \n",
    "    + K-Means Clustering\n",
    "    + Hierarchical Cluestering\n",
    "    + PCA (Principal Component Analysis)\n",
    "\n",
    "3) What are the test and validation set, and why would you want to use them?\n",
    "- We need to split our data 2 or 3 parts. First one is \"Training\", Second is \"Test\" and (optional) Third one is validation data.\n",
    "- Training data uses when we train the model. The training data is already has actual values.\n",
    "- With \"test\" data we have test data/test set which is basically a different data for which we know the values but this data was never shown to the model before. Thus if the model after training is performing good on test set as well then we can say that the Machine Learning model is good.\n",
    "- Data The validation dataset is different from the test dataset that is also held back from the training of the model, but is instead used to give an unbiased estimate of the skill of the final tuned model when comparing or selecting between final models.\n",
    "\n",
    "4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?\n",
    "- Data preprocessing is one of the most important step in ML as the quality of data and if we do not apply preprocessing step into our model, many problems may occur.\n",
    "\n",
    "#### 1-) Handling Null/Missing Values\n",
    "    - In the real-world dataset there are always null values. If we do not handle them our models will be misleading\n",
    "    - To detect them we could use (data is name of dataframe) data.isnull()\n",
    "    - method and it returns boolean to us. True means it is nan value\n",
    "    - İf we want to learn how many exist data.isnull().sum().sum()\n",
    "    - There are few methods to fill them \n",
    "        + Drop the whole column (data.dropna())\n",
    "        + Filling the values with mean of columns\n",
    "        + Filling the values with median/mode with the columns (SımpleImputer /KNN Imputer, Interpolation)\n",
    "                \n",
    "#### 2-) Standardization\n",
    "    - In standartization we transform our values such that mean of the value is 0 and the standart deviation is 1\n",
    "    - We need to complete the process the Since one feature has greater values than the other, it prevents it from being weighted in our model. To disturb them we do standardization\n",
    "    - Application is \n",
    "    - from sklearn.preprocessing import StandartScaler\n",
    "    - std = StandartScaler()\n",
    "    - X = data.fit_transform()\n",
    "    \n",
    "#### 3-) Handling Categorical Variables \n",
    "    - Categorical variables are basically the variables that are discrete and not continuous\n",
    "    - First of all we need to define our labels as Ordinal or Nominal variables\n",
    "    - Ordinal variables can be ordered such as sizes S<M<L \n",
    "    - For ordinal variables we could use map() function or LabelEncoder\n",
    "    - Example for map function \n",
    "    - size_mapping = {'M':1,'L':2}\n",
    "    - df_cat['size'] = df_cat['size'].map(size_mapping)\n",
    "    - Here M will be replaced w/ 1 and L = 2\n",
    "    \n",
    "    - Example for Label Encoder\n",
    "    - from sklearn.preprocessing import LabelEncoder\n",
    "    - class_le = LabelEncoder()\n",
    "    - df_cat['classlabel'] =\n",
    "    - class_le.fit_transform(df_cat['classlabel'].values)\n",
    "    - Here class1 will be represented with 0 and class2 with 1\n",
    "    \n",
    "#### 4-) One-Hot Encoding\n",
    "    - We use the One-Hot Encoding with Nominal Categorical Variables\n",
    "    - The easiest wat to use One-Hot Encoding is use get_dummies() function\n",
    "    - df_cat = pd.get_dummies(df_cat[['color','size','price']]),\n",
    "    - \n",
    "    red,\tgreen,\tblue\n",
    "    1,\t\t0,\t\t0\n",
    "    0,\t\t1,\t\t0\n",
    "    0,\t\t0,\t\t1 \n",
    "    - We could give numbers like that the non-ordinal variables \n",
    "    \n",
    "#### 5-) Multicolinearity\n",
    "    - Multicolinearity means there exists minimum 2 feature has high coleration with each other. It affects our model in a bad way so we need to drop one of the correlated feature the fix the problem \n",
    "    \n",
    "#### 6-) Outlier Detection \n",
    "    - Outlier values mislead our models weight and range so we need to drop them by using kind methods. Such as \n",
    "        + Standart Deviation\n",
    "        + Box Plots/IQR Calculation\n",
    "        + Isolation Forest\n",
    "\n",
    "5) How you can explore countionus and discrete variables?\n",
    "    - Both of them is numerical values and to recognize the differences between them let's check the informations below \n",
    "    - Discrete variables contains whole numerical values suchs as typically counts (Visits of dentist, cinemas etc.) In other words -Quantity of whose value changes- \n",
    "    \n",
    "    - Continous varibles can take any value within range ex(height in cm, pocket in depth in mm, etc.) In other words -Value is obtained by measuring- \n",
    "   \n",
    "6) Analyse the plot given below. (What is the plot and variable type, check the distribution and make comment about how you can preproccess it.)\n",
    "\n",
    "- Plot type is distplot provided by seaborn, we use this or histplot to see unvariate distrubiton of observations. This variable type is continious. To do preprocess it, we could do outlier detection, in this plot we could use many outliers which is misleading the model. Also we could do standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "References \n",
    "- https://www.guru99.com/supervised-vs-unsupervised-learning.html\n",
    "- https://www.guru99.com/unsupervised-machine-learning.html#:~:text=Unsupervised%20Learning%20Algorithms%20allow%20users,detection%2C%20neural%20networks%2C%20etc.\n",
    "- https://medium.com/t%C3%BCrkiye/makine-%C3%B6%C4%9Frenmesi-nedir-20dee450b56e\n",
    "- https://machinelearningmastery.com/difference-test-validation-datasets/\n",
    "- https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d \n",
    "- https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/discrete-vs-continuous-variables/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
